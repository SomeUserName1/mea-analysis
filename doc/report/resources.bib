@book{nylen2017neural,
  title={Neural Data Science: A Primer with MATLAB{\textregistered} and PythonTM},
  author={Nylen, Erik Lee and Wallisch, Pascal},
  year={2017},
  publisher={Academic Press}
}

@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@Article{         harris2020array,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@Article{Hunter:2007,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@article{donoghue2020parameterizing,
  title={Parameterizing neural power spectra into periodic and aperiodic components},
  author={Donoghue, Thomas and Haller, Matar and Peterson, Erik J and Varma, Paroma and Sebastian, Priyadarshini and Gao, Richard and Noto, Torben and Lara, Antonio H and Wallis, Joni D and Knight, Robert T and others},
  journal={Nature neuroscience},
  volume={23},
  number={12},
  pages={1655--1665},
  year={2020},
  publisher={Nature Publishing Group}
}



@inproceedings{0f6676b4112b417ba70c97456553d691,
title = "PyIF: A Fast and Light Weight Implementation to Estimate Bivariate Transfer Entropy for Big Data",
abstract = "Transfer entropy is an information measure that quantifies information flow between processes evolving in time. Transfer entropy has a plethora of potential applications in financial markets, canonical systems, neuroscience, and social media. We offer a fast open source Python implementation called PyIF that estimates Transfer Entropy with Kraskov's method. PyIF utilizes KD-Trees, multiple processes by parallelizing queries on said KD-Trees, and can be used with CUDA compatible GPUs to significantly reduce the wall time for estimating transfer entropy. We find from our analyses that PyIF's GPU implementation is up to 1072 times faster (and it's CPU implementation is up 181 times faster) than existing implementations to estimate transfer entropy on large data and scales better than existing implementatin. ",
keywords = "Parallel Processing, Transfer Entropy",
author = "Ikegwu, {Kelechi M.} and Jacob Trauger and Jeff McMullin and Brunner, {Robert J.}",
note = "Publisher Copyright: {\textcopyright} 2020 IEEE.; 2020 IEEE SoutheastCon, SoutheastCon 2020 ; Conference date: 28-03-2020 Through 29-03-2020",
year = "2020",
month = mar,
day = "28",
doi = "10.1109/SoutheastCon44009.2020.9249650",
language = "English (US)",
series = "Conference Proceedings - IEEE SOUTHEASTCON",
publisher = "Institute of Electrical and Electronics Engineers Inc.",
booktitle = "IEEE SoutheastCon 2020, SoutheastCon 2020",
address = "United States",

}

@article{mahadevan2022xenon,
  title={Xenon LFP Analysis Platform is a Novel Graphical User Interface for Analysis of Local Field Potential from Large-Scale MEA Recordings},
  author={Mahadevan, Arjun and Codadu, Neela K and Parrish, R Ryley},
  journal={bioRxiv},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}


@article{unakafova2019comparing,
  title={Comparing open-source toolboxes for processing and analysis of spike and local field potentials data},
  author={Unakafova, Valentina A and Gail, Alexander},
  journal={Frontiers in Neuroinformatics},
  volume={13},
  pages={57},
  year={2019},
  publisher={Frontiers Media SA}
}

@article{cotterill2019burst,
  title={Burst detection methods},
  author={Cotterill, Ellese and Eglen, Stephen J},
  journal={In Vitro Neuronal Networks},
  pages={185--206},
  year={2019},
  publisher={Springer}
}

@article{herreras2016local,
  title={Local field potentials: myths and misunderstandings},
  author={Herreras, Oscar},
  journal={Frontiers in neural circuits},
  volume={10},
  pages={101},
  year={2016},
  publisher={Frontiers Media SA}
}

@article{einevoll2013modelling,
  title={Modelling and analysis of local field potentials for studying the function of cortical circuits},
  author={Einevoll, Gaute T and Kayser, Christoph and Logothetis, Nikos K and Panzeri, Stefano},
  journal={Nature Reviews Neuroscience},
  volume={14},
  number={11},
  pages={770--785},
  year={2013},
  publisher={Nature Publishing Group}
}

@book{van2018signal,
  title={Signal processing for neuroscientists},
  author={Van Drongelen, Wim},
  year={2018},
  publisher={Academic press}
}

@ARTICLE{10.3389/fnins.2014.00423,
  
AUTHOR={Obien, Marie Engelene J. and Deligkaris, Kosmas and Bullmann, Torsten and Bakkum, Douglas J. and Frey, Urs},   
	 
TITLE={Revealing neuronal function through microelectrode array recordings},      
	
JOURNAL={Frontiers in Neuroscience},      
	
VOLUME={8},           
	
YEAR={2015},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fnins.2014.00423},       
	
DOI={10.3389/fnins.2014.00423},      
	
ISSN={1662-453X},   
   
ABSTRACT={Microelectrode arrays and microprobes have been widely utilized to measure neuronal activity, both in vitro and in vivo. The key advantage is the capability to record and stimulate neurons at multiple sites simultaneously. However, unlike the single-cell or single-channel resolution of intracellular recording, microelectrodes detect signals from all possible sources around every sensor. Here, we review the current understanding of microelectrode signals and the techniques for analyzing them. We introduce the ongoing advancements in microelectrode technology, with focus on achieving higher resolution and quality of recordings by means of monolithic integration with on-chip circuitry. We show how recent advanced microelectrode array measurement methods facilitate the understanding of single neurons as well as network function.}
}

@article{POTTER200117,
title = {A new approach to neural cell culture for long-term studies},
journal = {Journal of Neuroscience Methods},
volume = {110},
number = {1},
pages = {17-24},
year = {2001},
issn = {0165-0270},
doi = {https://doi.org/10.1016/S0165-0270(01)00412-5},
url = {https://www.sciencedirect.com/science/article/pii/S0165027001004125},
author = {Steve M Potter and Thomas B DeMarse},
keywords = {Cultured mammalian neurons, Multi-electrode arrays, Contamination, Hyperosmolality, Osmolarity, pH, Teflon membrane, Sealed culture chambers, Mold infection},
abstract = {We have developed a new method for culturing cells that maintains their health and sterility for many months. Using conventional techniques, primary neuron cultures seldom survive more than 2 months. Increases in the osmotic strength of media due to evaporation are a large and underappreciated contributor to the gradual decline in the health of these cultures. Because of this and the ever-present likelihood of contamination by airborne pathogens, repeated or extended experiments on any given culture have until now been difficult, if not impossible. We surmounted survival problems by using culture dish lids that form a gas-tight seal, and incorporate a transparent hydrophobic membrane (fluorinated ethyleneâ€“propylene) that is selectively permeable to oxygen (O2) and carbon dioxide (CO2), and relatively impermeable to water vapor. This prevents contamination and greatly reduces evaporation, allowing the use of a non-humidified incubator. We have employed this technique to grow dissociated cortical cultures from rat embryos on multi-electrode arrays. After more than a year in culture, the neurons still exhibit robust spontaneous electrical activity. The combination of sealed culture dishes with extracellular multi-electrode recording and stimulation enables study of development, adaptation, and very long-term plasticity, across months, in cultured neuronal networks. Membrane-sealed dishes will also be useful for the culture of many other cell types susceptible to evaporation and contamination.}
}

@incollection{POTTER200149,
title = {Chapter 4 Distributed processing in cultured neuronal networks},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {130},
pages = {49-62},
year = {2001},
booktitle = {Advances in Neural Population Coding},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(01)30005-5},
url = {https://www.sciencedirect.com/science/article/pii/S0079612301300055},
author = {Steve M. Potter},
abstract = {Publisher Summary
This chapter discusses efforts from a number of groups that lay the groundwork for an in vitro approach to study the population coding. Most researchers studying population coding are working with intact, living animals. The cultured neuronal networks lack many features of real brains, but they retain many others. They develop organotypic synaptic connections and exhibit a rich variety of distributed patterns of electrical activity. Progress in multi-electrode array technology, optical recording, and multi-photon microscopy, made it possible that every cell in a cultured monolayer network can be observed, monitored, stimulated, and manipulated with temporal resolution in the sub millisecond range, and spatial resolution in the submicron range, in a non-destructive manner. The nascent field of population coding in networks of cultured neurons is poised for rapid expansion. Neural cell culture, long-term multi-electrode recording and stimulation, and multi-single-unit optical recording are now accessible to many labs. Computers are fast and cheap enough to allow real-time spike analysis and stimulus generation, which makes it possible to give cultured networks a simulated body to behave with, and an environment to interact with. By allowing the culture to behave and receive sensory input, meaning can be ascribed to the patterns of electrical activity it produces, and persistent changes in network activity can be thought of as learning.}
}

@incollection{gross2006emerging,
  title={Emerging histiotypic properties of cultured neuronal networks},
  author={Gross, Guenter W and Gopal, Kamakshi V},
  booktitle={Advances in Network Electrophysiology},
  pages={193--214},
  year={2006},
  publisher={Springer}
}

@incollection{soussou2006mapping,
  title={Mapping spatio-temporal electrophysiological activity in hippocampal slices with conformal planar multi-electrode arrays},
  author={Soussou, Walid and Gholmieh, Ghassan and Han, Martin and Ahuja, Ashish and Song, Dong and Hsiao, Min-Chi and Wang, Zhuo and Tanguay, Armand R and Berger, Theodore W},
  booktitle={Advances in Network Electrophysiology},
  pages={127--152},
  year={2006},
  publisher={Springer}
}

@article{unakafova2019comparing,
  title={Comparing open-source toolboxes for processing and analysis of spike and local field potentials data},
  author={Unakafova, Valentina A and Gail, Alexander},
  journal={Frontiers in Neuroinformatics},
  volume={13},
  pages={57},
  year={2019},
  publisher={Frontiers Media SA}
}

@article{gramfort2014mne,
  title={MNE software for processing MEG and EEG data},
  author={Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A and Strohmeier, Daniel and Brodbeck, Christian and Parkkonen, Lauri and H{\"a}m{\"a}l{\"a}inen, Matti S},
  journal={Neuroimage},
  volume={86},
  pages={446--460},
  year={2014},
  publisher={Elsevier}
}

@article{oostenveld2011fieldtrip,
  title={FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data},
  author={Oostenveld, Robert and Fries, Pascal and Maris, Eric and Schoffelen, Jan-Mathijs},
  journal={Computational intelligence and neuroscience},
  volume={2011},
  year={2011},
  publisher={Hindawi}
}

@article{tadel2011brainstorm,
  title={Brainstorm: a user-friendly application for MEG/EEG analysis},
  author={Tadel, Fran{\c{c}}ois and Baillet, Sylvain and Mosher, John C and Pantazis, Dimitrios and Leahy, Richard M},
  journal={Computational intelligence and neuroscience},
  volume={2011},
  year={2011},
  publisher={Hindawi}
}

@book{williams2006electronic,
  title={Electronic filter design handbook},
  author={Williams, Arthur B and Taylor, Fred J},
  year={2006},
  publisher={McGraw-Hill Education}
}

@book{king2009hilbert,
  title={Hilbert transforms},
  author={King, Frederick W},
  volume={1},
  year={2009},
  publisher={Cambridge University Press Cambridge}
}

@ARTICLE{1161901,

  author={Welch, P.},

  journal={IEEE Transactions on Audio and Electroacoustics},

  title={The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms},

  year={1967},

  volume={15},

  number={2},

  pages={70-73},

  doi={10.1109/TAU.1967.1161901}}

@book{oppenheim1999discrete,
  title={Discrete-time signal processing},
  author={Oppenheim, Alan V},
  year={1999},
  publisher={Pearson Education India}
}

@article{nicholson1975theory,
  title={Theory of current source-density analysis and determination of conductivity tensor for anuran cerebellum},
  author={Nicholson, Charles and Freeman, JOHN A},
  journal={Journal of neurophysiology},
  volume={38},
  number={2},
  pages={356--368},
  year={1975},
  publisher={American Physiological Society Bethesda, MD}
}

